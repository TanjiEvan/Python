{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Phase 1: Data Cleaning & Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1: Load Dataset & Verify Structure**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SPPL IT\\AppData\\Local\\Temp\\ipykernel_10228\\3664851901.py:2: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('dataset 1.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset Loaded Successfully!\n",
      "üìå Shape of Data: (4526654, 24)\n",
      "\n",
      "üìù First 5 Rows:\n",
      "   Index        pH      Iron   Nitrate    Chloride Lead      Zinc  \\\n",
      "0      0  8.332988  0.000083  8.605777  122.799772  0.0  3.434827   \n",
      "1      1  6.917863  0.000081  3.734167  227.029851  0.0  1.245317   \n",
      "2      2  5.443762  0.020106  3.816994  230.995630  0.0  0.528280   \n",
      "3      3  7.955339  0.143988  8.224944  178.129940  0.0  4.027879   \n",
      "4      4  8.091909  0.002167  9.925788  186.540872  0.0  3.807511   \n",
      "\n",
      "            Color  Turbidity  Fluoride  ...  Chlorine     Manganese  \\\n",
      "0       Colorless   0.022683  0.607283  ...  3.708178  2.269945e-15   \n",
      "1    Faint Yellow   0.019007  0.622874  ...  3.292038  8.024076e-07   \n",
      "2    Light Yellow   0.319956  0.423423  ...  3.560224  7.007989e-02   \n",
      "3  Near Colorless   0.166319  0.208454  ...  3.516907  2.468295e-02   \n",
      "4    Light Yellow   0.004867  0.222912  ...  3.177849  3.296139e-03   \n",
      "\n",
      "   Total Dissolved Solids  Source  Water Temperature  Air Temperature  \\\n",
      "0              332.118789     NaN                NaN        43.493324   \n",
      "1              284.641984    Lake          15.348981        71.220586   \n",
      "2              570.054094   River          11.643467        44.891330   \n",
      "3              100.043838  Ground          10.092392        60.843233   \n",
      "4              168.075545  Spring          15.249416        69.336671   \n",
      "\n",
      "      Month   Day  Time of Day  Target  \n",
      "0   January  29.0          4.0     0.0  \n",
      "1  November  26.0         16.0     0.0  \n",
      "2   January  31.0          8.0     0.0  \n",
      "3     April   1.0         21.0     0.0  \n",
      "4      June  29.0          7.0     0.0  \n",
      "\n",
      "[5 rows x 24 columns]\n",
      "\n",
      "‚ö†Ô∏è Missing Values Per Column:\n",
      "Index                          0\n",
      "pH                         87993\n",
      "Iron                       30268\n",
      "Nitrate                    80327\n",
      "Chloride                  133284\n",
      "Lead                       20379\n",
      "Zinc                      118656\n",
      "Color                       4347\n",
      "Turbidity                  37925\n",
      "Fluoride                  143819\n",
      "Copper                    151897\n",
      "Odor                      135592\n",
      "Sulfate                   149935\n",
      "Conductivity              124734\n",
      "Chlorine                   43995\n",
      "Manganese                  83288\n",
      "Total Dissolved Solids      1285\n",
      "Source                     67087\n",
      "Water Temperature         127378\n",
      "Air Temperature            22753\n",
      "Month                      72541\n",
      "Day                        75838\n",
      "Time of Day                86730\n",
      "Target                         1\n",
      "dtype: int64\n",
      "\n",
      "üõ† Column Data Types:\n",
      "Index                       int64\n",
      "pH                        float64\n",
      "Iron                      float64\n",
      "Nitrate                   float64\n",
      "Chloride                  float64\n",
      "Lead                       object\n",
      "Zinc                      float64\n",
      "Color                      object\n",
      "Turbidity                 float64\n",
      "Fluoride                  float64\n",
      "Copper                    float64\n",
      "Odor                      float64\n",
      "Sulfate                   float64\n",
      "Conductivity              float64\n",
      "Chlorine                  float64\n",
      "Manganese                 float64\n",
      "Total Dissolved Solids    float64\n",
      "Source                     object\n",
      "Water Temperature         float64\n",
      "Air Temperature           float64\n",
      "Month                      object\n",
      "Day                       float64\n",
      "Time of Day               float64\n",
      "Target                    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('dataset 1.csv')   \n",
    "\n",
    "# Display basic info\n",
    "print(\"‚úÖ Dataset Loaded Successfully!\")\n",
    "print(\"üìå Shape of Data:\", df.shape)\n",
    "print(\"\\nüìù First 5 Rows:\")\n",
    "print(df.head())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\n‚ö†Ô∏è Missing Values Per Column:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Check data types\n",
    "print(\"\\nüõ† Column Data Types:\")\n",
    "print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(\"Index\",axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2.1: Fixing Data Types**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Updated Data Types:\n",
      " pH                         float64\n",
      "Iron                       float64\n",
      "Nitrate                    float64\n",
      "Chloride                   float64\n",
      "Lead                       float64\n",
      "Zinc                       float64\n",
      "Color                     category\n",
      "Turbidity                  float64\n",
      "Fluoride                   float64\n",
      "Copper                     float64\n",
      "Odor                       float64\n",
      "Sulfate                    float64\n",
      "Conductivity               float64\n",
      "Chlorine                   float64\n",
      "Manganese                  float64\n",
      "Total Dissolved Solids     float64\n",
      "Source                    category\n",
      "Water Temperature          float64\n",
      "Air Temperature            float64\n",
      "Month                     category\n",
      "Day                        float64\n",
      "Time of Day                float64\n",
      "Target                     float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Convert 'Lead' column to numeric (force errors='coerce' to convert non-numeric to NaN)\n",
    "df[\"Lead\"] = pd.to_numeric(df[\"Lead\"], errors=\"coerce\")\n",
    "\n",
    "# Convert 'Month' to categorical \n",
    "df[\"Month\"] = df[\"Month\"].astype(\"category\")\n",
    "\n",
    "# Convert categorical text columns to category type\n",
    "df[\"Source\"] = df[\"Source\"].astype(\"category\")\n",
    "df[\"Color\"] = df[\"Color\"].astype(\"category\")\n",
    "\n",
    "# Verify data types after conversion\n",
    "print(\"‚úÖ Updated Data Types:\\n\", df.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2.2: Handling Missing Values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Missing Values Per Column:\n",
      " pH                         87993\n",
      "Iron                       30268\n",
      "Nitrate                    80327\n",
      "Chloride                  133284\n",
      "Lead                       20380\n",
      "Zinc                      118656\n",
      "Color                       4347\n",
      "Turbidity                  37925\n",
      "Fluoride                  143819\n",
      "Copper                    151897\n",
      "Odor                      135592\n",
      "Sulfate                   149935\n",
      "Conductivity              124734\n",
      "Chlorine                   43995\n",
      "Manganese                  83288\n",
      "Total Dissolved Solids      1285\n",
      "Source                     67087\n",
      "Water Temperature         127378\n",
      "Air Temperature            22753\n",
      "Month                      72541\n",
      "Day                        75838\n",
      "Time of Day                86730\n",
      "Target                         1\n",
      "dtype: int64\n",
      "\n",
      "üìå Total Missing Values: 1800053\n",
      "\n",
      "üìù Dataset Shape Before Handling Missing Values: (4526654, 23)\n"
     ]
    }
   ],
   "source": [
    "# Check missing values\n",
    "missing_values = df.isnull().sum()\n",
    "\n",
    "print(\"‚ö†Ô∏è Missing Values Per Column:\\n\", missing_values)\n",
    "print(\"\\nüìå Total Missing Values:\", missing_values.sum())\n",
    "\n",
    "# Display basic stats before handling missing values\n",
    "print(\"\\nüìù Dataset Shape Before Handling Missing Values:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Missing Values After Handling:\n",
      "pH                        0\n",
      "Iron                      0\n",
      "Nitrate                   0\n",
      "Chloride                  0\n",
      "Lead                      0\n",
      "Zinc                      0\n",
      "Color                     0\n",
      "Turbidity                 0\n",
      "Fluoride                  0\n",
      "Copper                    0\n",
      "Odor                      0\n",
      "Sulfate                   0\n",
      "Conductivity              0\n",
      "Chlorine                  0\n",
      "Manganese                 0\n",
      "Total Dissolved Solids    0\n",
      "Source                    0\n",
      "Water Temperature         0\n",
      "Air Temperature           0\n",
      "Month                     0\n",
      "Day                       0\n",
      "Time of Day               0\n",
      "Target                    0\n",
      "dtype: int64\n",
      "\n",
      "üìå Dataset Shape After Handling Missing Values: (4526653, 23)\n"
     ]
    }
   ],
   "source": [
    "# Drop rows where Target is missing (since it's only 1 row)\n",
    "df = df.dropna(subset=['Target'])\n",
    "\n",
    "# Fill missing values for numerical columns with median\n",
    "num_cols = df.select_dtypes(include=['float64']).columns\n",
    "df[num_cols] = df[num_cols].fillna(df[num_cols].median())\n",
    "\n",
    "# Fill missing values for categorical columns with mode (most frequent value)\n",
    "cat_cols = df.select_dtypes(include=['category']).columns\n",
    "df[cat_cols] = df[cat_cols].apply(lambda x: x.fillna(x.mode()[0]))\n",
    "\n",
    "# Verify that missing values are handled\n",
    "print(\"‚úÖ Missing Values After Handling:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Display dataset shape after handling missing values\n",
    "print(\"\\nüìå Dataset Shape After Handling Missing Values:\", df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2.3: Handling Invalid Values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Invalid (Negative) Values Found:\n",
      "        pH  Iron  Nitrate  Chloride  Lead  Zinc  Turbidity  Fluoride  Copper  \\\n",
      "count  0.0   0.0      0.0       0.0   0.0   0.0        0.0       0.0     0.0   \n",
      "mean   NaN   NaN      NaN       NaN   NaN   NaN        NaN       NaN     NaN   \n",
      "std    NaN   NaN      NaN       NaN   NaN   NaN        NaN       NaN     NaN   \n",
      "min    NaN   NaN      NaN       NaN   NaN   NaN        NaN       NaN     NaN   \n",
      "25%    NaN   NaN      NaN       NaN   NaN   NaN        NaN       NaN     NaN   \n",
      "50%    NaN   NaN      NaN       NaN   NaN   NaN        NaN       NaN     NaN   \n",
      "75%    NaN   NaN      NaN       NaN   NaN   NaN        NaN       NaN     NaN   \n",
      "max    NaN   NaN      NaN       NaN   NaN   NaN        NaN       NaN     NaN   \n",
      "\n",
      "       Odor  Sulfate  Conductivity  Chlorine  Manganese  \\\n",
      "count   0.0      0.0           0.0       0.0        0.0   \n",
      "mean    NaN      NaN           NaN       NaN        NaN   \n",
      "std     NaN      NaN           NaN       NaN        NaN   \n",
      "min     NaN      NaN           NaN       NaN        NaN   \n",
      "25%     NaN      NaN           NaN       NaN        NaN   \n",
      "50%     NaN      NaN           NaN       NaN        NaN   \n",
      "75%     NaN      NaN           NaN       NaN        NaN   \n",
      "max     NaN      NaN           NaN       NaN        NaN   \n",
      "\n",
      "       Total Dissolved Solids  Water Temperature  Air Temperature  Day  \\\n",
      "count                     0.0                0.0      2127.000000  0.0   \n",
      "mean                      NaN                NaN        -4.814479  NaN   \n",
      "std                       NaN                NaN         4.450453  NaN   \n",
      "min                       NaN                NaN       -33.870915  NaN   \n",
      "25%                       NaN                NaN        -6.795079  NaN   \n",
      "50%                       NaN                NaN        -3.557515  NaN   \n",
      "75%                       NaN                NaN        -1.533558  NaN   \n",
      "max                       NaN                NaN        -0.001248  NaN   \n",
      "\n",
      "       Time of Day  Target  \n",
      "count          0.0     0.0  \n",
      "mean           NaN     NaN  \n",
      "std            NaN     NaN  \n",
      "min            NaN     NaN  \n",
      "25%            NaN     NaN  \n",
      "50%            NaN     NaN  \n",
      "75%            NaN     NaN  \n",
      "max            NaN     NaN  \n",
      "\n",
      "‚úÖ Invalid Value Check Completed!\n"
     ]
    }
   ],
   "source": [
    "# Find negative values\n",
    "invalid_values = df[num_cols][df[num_cols] < 0]\n",
    "\n",
    "# Print results\n",
    "print(\"‚ö†Ô∏è Invalid (Negative) Values Found:\")\n",
    "print(invalid_values.describe())\n",
    "\n",
    "\n",
    "print(\"\\n‚úÖ Invalid Value Check Completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Negative Values Removed Successfully!\n",
      "\n",
      "‚ö†Ô∏è Remaining Negative Values:\n",
      "pH                        0\n",
      "Iron                      0\n",
      "Nitrate                   0\n",
      "Chloride                  0\n",
      "Lead                      0\n",
      "Zinc                      0\n",
      "Turbidity                 0\n",
      "Fluoride                  0\n",
      "Copper                    0\n",
      "Odor                      0\n",
      "Sulfate                   0\n",
      "Conductivity              0\n",
      "Chlorine                  0\n",
      "Manganese                 0\n",
      "Total Dissolved Solids    0\n",
      "Water Temperature         0\n",
      "Air Temperature           0\n",
      "Day                       0\n",
      "Time of Day               0\n",
      "Target                    0\n",
      "dtype: int64\n",
      "\n",
      "üìå Dataset Shape After Removing Negative Values: (4524526, 23)\n"
     ]
    }
   ],
   "source": [
    "# Remove rows containing negative values in any numerical column\n",
    "df = df[(df[num_cols] >= 0).all(axis=1)].copy()\n",
    "\n",
    "# Verify if any negative values remain\n",
    "negative_check = (df[num_cols] < 0).sum()\n",
    "\n",
    "# Display confirmation\n",
    "print(\"‚úÖ Negative Values Removed Successfully!\")\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è Remaining Negative Values:\")\n",
    "print(negative_check)\n",
    "\n",
    "# Check dataset shape after dropping invalid rows\n",
    "print(\"\\nüìå Dataset Shape After Removing Negative Values:\", df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2.3: Outlier Handling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 pH          Iron       Nitrate      Chloride           Lead  \\\n",
      "count  4.524526e+06  4.524526e+06  4.524526e+06  4.524526e+06   4.524526e+06   \n",
      "mean   7.445999e+00  1.252322e-01  6.147248e+00  1.837081e+02   1.459541e-03   \n",
      "std    8.741905e-01  4.740444e-01  3.211280e+00  6.703719e+01   3.205737e-02   \n",
      "min    1.057113e+00  2.047587e-53  2.861727e-01  2.363919e+01   0.000000e+00   \n",
      "25%    6.908848e+00  1.041383e-05  4.000400e+00  1.392692e+02  3.368981e-122   \n",
      "50%    7.450047e+00  2.226640e-03  5.599301e+00  1.758433e+02   2.137893e-62   \n",
      "75%    8.000353e+00  5.298038e-02  7.613478e+00  2.161728e+02   2.494635e-27   \n",
      "max    1.291072e+01  1.935315e+01  9.639078e+01  1.507310e+03   5.844281e+00   \n",
      "\n",
      "               Zinc     Turbidity      Fluoride        Copper          Odor  \\\n",
      "count  4.524526e+06  4.524526e+06  4.524526e+06  4.524526e+06  4.524526e+06   \n",
      "mean   1.534867e+00  5.137011e-01  9.551685e-01  5.074587e-01  1.797618e+00   \n",
      "std    1.522185e+00  9.136822e-01  8.076025e-01  5.832484e-01  1.050917e+00   \n",
      "min    1.482707e-08  1.029712e-16  4.550148e-06  1.725879e-09  1.100007e-02   \n",
      "25%    4.287878e-01  3.927043e-02  3.863658e-01  1.345659e-01  9.166553e-01   \n",
      "50%    1.080595e+00  2.083245e-01  7.739789e-01  3.465941e-01  1.769302e+00   \n",
      "75%    2.184815e+00  6.153921e-01  1.314557e+00  6.819998e-01  2.620584e+00   \n",
      "max    2.836867e+01  2.371527e+01  1.464625e+01  1.207482e+01  4.141998e+00   \n",
      "\n",
      "            Sulfate  Conductivity      Chlorine     Manganese  \\\n",
      "count  4.524526e+06  4.524526e+06  4.524526e+06  4.524526e+06   \n",
      "mean   1.455225e+02  4.241520e+02  3.252893e+00  1.050585e-01   \n",
      "std    6.741715e+01  1.873794e+02  7.268236e-01  4.670461e-01   \n",
      "min    1.194073e+01  1.059998e+01  9.019921e-01  1.214196e-54   \n",
      "25%    9.898472e+01  2.895707e+02  2.748849e+00  2.854350e-06   \n",
      "50%    1.345632e+02  3.970287e+02  3.208491e+00  6.318782e-04   \n",
      "75%    1.795907e+02  5.283602e+02  3.696944e+00  1.547106e-02   \n",
      "max    1.434587e+03  2.271632e+03  1.256663e+01  2.374086e+01   \n",
      "\n",
      "       Total Dissolved Solids  Water Temperature  Air Temperature  \\\n",
      "count            4.524526e+06       4.524526e+06     4.524526e+06   \n",
      "mean             2.667758e+02       1.905780e+01     6.003602e+01   \n",
      "std              1.556208e+02       1.121644e+01     1.800913e+01   \n",
      "min              1.052297e-02       6.661938e-01     8.586156e-03   \n",
      "25%              1.327169e+02       1.149414e+01     4.788395e+01   \n",
      "50%              2.654942e+02       1.644824e+01     5.999766e+01   \n",
      "75%              3.979487e+02       2.354011e+01     7.215320e+01   \n",
      "max              5.797999e+02       2.568117e+02     1.521237e+02   \n",
      "\n",
      "                Day   Time of Day        Target  \n",
      "count  4.524526e+06  4.524526e+06  4.524526e+06  \n",
      "mean   1.573393e+01  1.151278e+01  2.924680e-01  \n",
      "std    8.722004e+00  6.856843e+00  4.548962e-01  \n",
      "min    1.000000e+00  0.000000e+00  0.000000e+00  \n",
      "25%    8.000000e+00  6.000000e+00  0.000000e+00  \n",
      "50%    1.600000e+01  1.200000e+01  0.000000e+00  \n",
      "75%    2.300000e+01  1.700000e+01  1.000000e+00  \n",
      "max    3.100000e+01  2.300000e+01  1.000000e+00  \n"
     ]
    }
   ],
   "source": [
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Winsorization Completed!\n",
      "üìå Final Dataset Shape: (4524526, 23)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats.mstats import winsorize\n",
    "\n",
    "# 1Ô∏è‚É£ Exclude only 'Target' column (binary column) from winsorization\n",
    "winsorize_cols = [col for col in num_cols if col != 'Target']  # Use num_cols and exclude Target\n",
    "\n",
    "# 2Ô∏è‚É£ Apply Winsorization (Capping at 1st & 99th Percentile)\n",
    "for col in winsorize_cols:\n",
    "    df[col] = winsorize(df[col], limits=[0.01, 0.01])  # Capping at 1st and 99th percentile\n",
    "\n",
    "# ‚úÖ Winsorization Applied!\n",
    "print(\"‚úÖ Winsorization Completed!\")\n",
    "\n",
    "print(\"üìå Final Dataset Shape:\", df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# **Outlier Handling Using Winsorization**\n",
    "\n",
    "## **What is Winsorization?**\n",
    "Winsorization is a **statistical transformation** technique used to reduce the effect of **extreme outliers** by **limiting** (capping) values instead of removing them. Unlike traditional outlier removal methods (e.g., Interquartile Range (IQR) method), Winsorization **does not remove data points** but instead **modifies extreme values** to a predefined threshold.\n",
    "\n",
    "---\n",
    "\n",
    "## **Why Use Winsorization Instead of Removing Outliers?**\n",
    "- **Preserves data integrity**: Unlike outright removal, Winsorization ensures we **retain all data points** while preventing extreme values from distorting our analysis.\n",
    "- **Prevents information loss**: In datasets where **outliers carry meaningful information**, removing them entirely could result in loss of critical insights.\n",
    "- **Works well for skewed data**: Many real-world datasets, especially environmental and water quality data, contain **naturally occurring extreme values** that shouldn't be removed.\n",
    "\n",
    "---\n",
    "\n",
    "## **How Does Winsorization Work?**\n",
    "- Winsorization replaces **extreme values** at both ends of the distribution **with the closest threshold values**.\n",
    "- Instead of completely removing outliers, **values beyond a certain percentile are capped**.\n",
    "- This ensures that **outliers do not dominate** the analysis while keeping their presence in the dataset.\n",
    "\n",
    "---\n",
    "\n",
    "## **What Does `[0.01, 0.01]` Mean?**\n",
    "- The two values `[0.01, 0.01]` represent the **percentage of data** to be **Winsorized** at both ends of the distribution.\n",
    "- **0.01 (1%) at the lower end**: This means that the **lowest 1% of values** are **replaced** with the **value at the 1st percentile**.\n",
    "- **0.01 (1%) at the upper end**: The **highest 1% of values** are **replaced** with the value at the 99th percentile.\n",
    "- The Winsorization range ensures that **only the most extreme outliers are modified**, keeping the data more representative of the underlying distribution.\n",
    "\n",
    "---\n",
    "\n",
    "## **Why Specifically the 1st and 99th Percentile?**\n",
    "- The **1st and 99th percentile** were chosen as a **balanced approach**:\n",
    "  - It **removes the extreme 1% tail on both ends** without affecting the majority of the data.\n",
    "  - This is common in **environmental and water quality data**, where some natural variability is expected but extreme values may be due to sensor errors or rare contamination events.\n",
    "  - It avoids **over-smoothing** the data, ensuring that useful information from higher percentiles (e.g., 5th and 95th) remains intact.\n",
    "\n",
    "---\n",
    "\n",
    "## **Summary of Our Winsorization Process**\n",
    "- **We applied Winsorization to all numerical columns except ‚ÄòTarget‚Äô** (since it is a binary classification variable).\n",
    "- **Extreme values were capped at the 1st and 99th percentile**.\n",
    "- **No rows were removed**, ensuring all data points remain available for analysis.\n",
    "- **This helps reduce the effect of extreme outliers** while preserving meaningful trends in the dataset.\n",
    "\n",
    "---\n",
    "\n",
    "### **‚úÖ Winsorization Completed Successfully!**\n",
    "This ensures our dataset is **cleaned from extreme distortions** while retaining its overall distribution for accurate analysis and machine learning models.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "x:\\Data Science\\deep_env\\lib\\site-packages\\numpy\\lib\\_function_base_impl.py:4968: UserWarning: Warning: 'partition' will ignore the 'mask' of the MaskedArray.\n",
      "  arr.partition(\n",
      "x:\\Data Science\\deep_env\\lib\\site-packages\\numpy\\lib\\_function_base_impl.py:4968: UserWarning: Warning: 'partition' will ignore the 'mask' of the MaskedArray.\n",
      "  arr.partition(\n",
      "x:\\Data Science\\deep_env\\lib\\site-packages\\numpy\\lib\\_function_base_impl.py:4968: UserWarning: Warning: 'partition' will ignore the 'mask' of the MaskedArray.\n",
      "  arr.partition(\n",
      "x:\\Data Science\\deep_env\\lib\\site-packages\\numpy\\lib\\_function_base_impl.py:4968: UserWarning: Warning: 'partition' will ignore the 'mask' of the MaskedArray.\n",
      "  arr.partition(\n",
      "x:\\Data Science\\deep_env\\lib\\site-packages\\numpy\\lib\\_function_base_impl.py:4968: UserWarning: Warning: 'partition' will ignore the 'mask' of the MaskedArray.\n",
      "  arr.partition(\n",
      "x:\\Data Science\\deep_env\\lib\\site-packages\\numpy\\lib\\_function_base_impl.py:4968: UserWarning: Warning: 'partition' will ignore the 'mask' of the MaskedArray.\n",
      "  arr.partition(\n",
      "x:\\Data Science\\deep_env\\lib\\site-packages\\numpy\\lib\\_function_base_impl.py:4968: UserWarning: Warning: 'partition' will ignore the 'mask' of the MaskedArray.\n",
      "  arr.partition(\n",
      "x:\\Data Science\\deep_env\\lib\\site-packages\\numpy\\lib\\_function_base_impl.py:4968: UserWarning: Warning: 'partition' will ignore the 'mask' of the MaskedArray.\n",
      "  arr.partition(\n",
      "x:\\Data Science\\deep_env\\lib\\site-packages\\numpy\\lib\\_function_base_impl.py:4968: UserWarning: Warning: 'partition' will ignore the 'mask' of the MaskedArray.\n",
      "  arr.partition(\n",
      "x:\\Data Science\\deep_env\\lib\\site-packages\\numpy\\lib\\_function_base_impl.py:4968: UserWarning: Warning: 'partition' will ignore the 'mask' of the MaskedArray.\n",
      "  arr.partition(\n",
      "x:\\Data Science\\deep_env\\lib\\site-packages\\numpy\\lib\\_function_base_impl.py:4968: UserWarning: Warning: 'partition' will ignore the 'mask' of the MaskedArray.\n",
      "  arr.partition(\n",
      "x:\\Data Science\\deep_env\\lib\\site-packages\\numpy\\lib\\_function_base_impl.py:4968: UserWarning: Warning: 'partition' will ignore the 'mask' of the MaskedArray.\n",
      "  arr.partition(\n",
      "x:\\Data Science\\deep_env\\lib\\site-packages\\numpy\\lib\\_function_base_impl.py:4968: UserWarning: Warning: 'partition' will ignore the 'mask' of the MaskedArray.\n",
      "  arr.partition(\n",
      "x:\\Data Science\\deep_env\\lib\\site-packages\\numpy\\lib\\_function_base_impl.py:4968: UserWarning: Warning: 'partition' will ignore the 'mask' of the MaskedArray.\n",
      "  arr.partition(\n",
      "x:\\Data Science\\deep_env\\lib\\site-packages\\numpy\\lib\\_function_base_impl.py:4968: UserWarning: Warning: 'partition' will ignore the 'mask' of the MaskedArray.\n",
      "  arr.partition(\n",
      "x:\\Data Science\\deep_env\\lib\\site-packages\\numpy\\lib\\_function_base_impl.py:4968: UserWarning: Warning: 'partition' will ignore the 'mask' of the MaskedArray.\n",
      "  arr.partition(\n",
      "x:\\Data Science\\deep_env\\lib\\site-packages\\numpy\\lib\\_function_base_impl.py:4968: UserWarning: Warning: 'partition' will ignore the 'mask' of the MaskedArray.\n",
      "  arr.partition(\n",
      "x:\\Data Science\\deep_env\\lib\\site-packages\\numpy\\lib\\_function_base_impl.py:4968: UserWarning: Warning: 'partition' will ignore the 'mask' of the MaskedArray.\n",
      "  arr.partition(\n",
      "x:\\Data Science\\deep_env\\lib\\site-packages\\numpy\\lib\\_function_base_impl.py:4968: UserWarning: Warning: 'partition' will ignore the 'mask' of the MaskedArray.\n",
      "  arr.partition(\n",
      "x:\\Data Science\\deep_env\\lib\\site-packages\\numpy\\lib\\_function_base_impl.py:4968: UserWarning: Warning: 'partition' will ignore the 'mask' of the MaskedArray.\n",
      "  arr.partition(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 pH          Iron       Nitrate      Chloride           Lead  \\\n",
      "count  4.524526e+06  4.524526e+06  4.524526e+06  4.524526e+06   4.524526e+06   \n",
      "mean   7.446013e+00  1.107651e-01  6.104349e+00  1.830621e+02   6.188506e-05   \n",
      "std    8.451137e-01  3.396725e-01  2.960492e+00  6.337548e+01   4.589861e-04   \n",
      "min    5.037333e+00  1.200793e-16  1.645919e+00  7.357661e+01   0.000000e+00   \n",
      "25%    6.908848e+00  1.041383e-05  4.000400e+00  1.392692e+02  3.368981e-122   \n",
      "50%    7.450047e+00  2.226640e-03  5.599301e+00  1.758433e+02   2.137893e-62   \n",
      "75%    8.000353e+00  5.298038e-02  7.613478e+00  2.161728e+02   2.494635e-27   \n",
      "max    9.767686e+00  2.343167e+00  1.789541e+01  4.188014e+02   4.147569e-03   \n",
      "\n",
      "               Zinc     Turbidity      Fluoride        Copper          Odor  \\\n",
      "count  4.524526e+06  4.524526e+06  4.524526e+06  4.524526e+06  4.524526e+06   \n",
      "mean   1.515383e+00  4.964433e-01  9.453987e-01  4.987727e-01  1.797284e+00   \n",
      "std    1.425508e+00  7.938897e-01  7.565366e-01  5.316448e-01  1.049497e+00   \n",
      "min    9.658471e-03  2.045977e-05  2.498144e-02  2.211165e-03  4.727271e-02   \n",
      "25%    4.287878e-01  3.927043e-02  3.863658e-01  1.345659e-01  9.166553e-01   \n",
      "50%    1.080595e+00  2.083245e-01  7.739789e-01  3.465941e-01  1.769302e+00   \n",
      "75%    2.184815e+00  6.153921e-01  1.314557e+00  6.819998e-01  2.620584e+00   \n",
      "max    6.855268e+00  4.662328e+00  3.992915e+00  2.938214e+00  4.038896e+00   \n",
      "\n",
      "            Sulfate  Conductivity      Chlorine     Manganese  \\\n",
      "count  4.524526e+06  4.524526e+06  4.524526e+06  4.524526e+06   \n",
      "mean   1.447355e+02  4.231718e+02  3.248719e+00  9.049595e-02   \n",
      "std    6.310761e+01  1.826457e+02  7.022713e-01  3.296538e-01   \n",
      "min    4.373081e+01  1.094931e+02  1.837823e+00  1.897774e-17   \n",
      "25%    9.898472e+01  2.895707e+02  2.748849e+00  2.854350e-06   \n",
      "50%    1.345632e+02  3.970287e+02  3.208491e+00  6.318782e-04   \n",
      "75%    1.795907e+02  5.283602e+02  3.696944e+00  1.547106e-02   \n",
      "max    3.768602e+02  9.815772e+02  5.437203e+00  2.284421e+00   \n",
      "\n",
      "       Total Dissolved Solids  Water Temperature  Air Temperature  \\\n",
      "count            4.524526e+06       4.524526e+06     4.524526e+06   \n",
      "mean             2.667330e+02       1.893290e+01     6.002895e+01   \n",
      "std              1.554402e+02       1.054865e+01     1.770636e+01   \n",
      "min              5.330682e+00       4.599736e+00     1.822019e+01   \n",
      "25%              1.327169e+02       1.149414e+01     4.788395e+01   \n",
      "50%              2.654942e+02       1.644824e+01     5.999766e+01   \n",
      "75%              3.979487e+02       2.354011e+01     7.215320e+01   \n",
      "max              5.658999e+02       5.875529e+01     1.020763e+02   \n",
      "\n",
      "                Day   Time of Day        Target  \n",
      "count  4.524526e+06  4.524526e+06  4.524526e+06  \n",
      "mean   1.573393e+01  1.151278e+01  2.924680e-01  \n",
      "std    8.722004e+00  6.856843e+00  4.548962e-01  \n",
      "min    1.000000e+00  0.000000e+00  0.000000e+00  \n",
      "25%    8.000000e+00  6.000000e+00  0.000000e+00  \n",
      "50%    1.600000e+01  1.200000e+01  0.000000e+00  \n",
      "75%    2.300000e+01  1.700000e+01  1.000000e+00  \n",
      "max    3.100000e+01  2.300000e+01  1.000000e+00  \n"
     ]
    }
   ],
   "source": [
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**One-Hot Encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ One-Hot Encoding Completed!\n",
      "üìå Updated Dataset Shape: (4524526, 42)\n",
      "üìù First 5 Rows After Encoding:\n",
      "          pH      Iron   Nitrate    Chloride           Lead      Zinc  \\\n",
      "0  8.332988  0.000083  8.605777  122.799772   3.713298e-52  3.434827   \n",
      "1  6.917863  0.000081  3.734167  227.029851   7.849262e-94  1.245317   \n",
      "2  5.443762  0.020106  3.816994  230.995630   5.286616e-76  0.528280   \n",
      "3  7.955339  0.143988  8.224944  178.129940  3.997118e-176  4.027879   \n",
      "4  8.091909  0.002167  9.925788  186.540872  4.171069e-132  3.807511   \n",
      "\n",
      "   Turbidity  Fluoride    Copper      Odor  ...  Month_December  \\\n",
      "0   0.022683  0.607283  0.144599  1.626212  ...           False   \n",
      "1   0.019007  0.622874  0.437835  1.686049  ...           False   \n",
      "2   0.319956  0.423423  0.431588  3.414619  ...           False   \n",
      "3   0.166319  0.208454  0.239451  1.769302  ...           False   \n",
      "4   0.004867  0.222912  0.616574  0.795310  ...           False   \n",
      "\n",
      "   Month_February  Month_January  Month_July  Month_June  Month_March  \\\n",
      "0           False           True       False       False        False   \n",
      "1           False          False       False       False        False   \n",
      "2           False           True       False       False        False   \n",
      "3           False          False       False       False        False   \n",
      "4           False          False       False        True        False   \n",
      "\n",
      "   Month_May  Month_November  Month_October  Month_September  \n",
      "0      False           False          False            False  \n",
      "1      False            True          False            False  \n",
      "2      False           False          False            False  \n",
      "3      False           False          False            False  \n",
      "4      False           False          False            False  \n",
      "\n",
      "[5 rows x 42 columns]\n"
     ]
    }
   ],
   "source": [
    "# Categorical Columns\n",
    "categorical_cols = [\"Color\", \"Source\", \"Month\"]\n",
    "\n",
    "# Apply One-Hot Encoding\n",
    "df_encoded = pd.get_dummies(df, columns=categorical_cols, drop_first=True)  # Drop first category to avoid dummy trap\n",
    "\n",
    "# Check Updated Data\n",
    "print(\"‚úÖ One-Hot Encoding Completed!\")\n",
    "print(\"üìå Updated Dataset Shape:\", df_encoded.shape)\n",
    "print(\"üìù First 5 Rows After Encoding:\\n\", df_encoded.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded.to_csv(\"cleaned_dataset.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Phase:2 Feature Selection**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Information Gain Calculation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Use the Correct DataFrame (After Encoding)\n",
    "X = df_encoded.drop(columns=[\"Target\"])  # All features except Target\n",
    "y = df_encoded[\"Target\"]  # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 97.7 MiB for an array with shape (3201247, 4) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"x:\\Data Science\\deep_env\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 463, in _process_worker\n    r = call_item()\n  File \"x:\\Data Science\\deep_env\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 291, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"x:\\Data Science\\deep_env\\lib\\site-packages\\joblib\\parallel.py\", line 598, in __call__\n    return [func(*args, **kwargs)\n  File \"x:\\Data Science\\deep_env\\lib\\site-packages\\joblib\\parallel.py\", line 598, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"x:\\Data Science\\deep_env\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 139, in __call__\n    return self.function(*args, **kwargs)\n  File \"x:\\Data Science\\deep_env\\lib\\site-packages\\sklearn\\feature_selection\\_mutual_info.py\", line 167, in _compute_mi\n    return _compute_mi_cd(x, y, n_neighbors)\n  File \"x:\\Data Science\\deep_env\\lib\\site-packages\\sklearn\\feature_selection\\_mutual_info.py\", line 129, in _compute_mi_cd\n    r = nn.kneighbors()[0]\n  File \"x:\\Data Science\\deep_env\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 923, in kneighbors\n    chunked_results = Parallel(n_jobs, prefer=\"threads\")(\n  File \"x:\\Data Science\\deep_env\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 77, in __call__\n    return super().__call__(iterable_with_config)\n  File \"x:\\Data Science\\deep_env\\lib\\site-packages\\joblib\\parallel.py\", line 1918, in __call__\n    return output if self.return_generator else list(output)\n  File \"x:\\Data Science\\deep_env\\lib\\site-packages\\joblib\\parallel.py\", line 1847, in _get_sequential_output\n    res = func(*args, **kwargs)\n  File \"x:\\Data Science\\deep_env\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 139, in __call__\n    return self.function(*args, **kwargs)\n  File \"sklearn\\\\neighbors\\\\_binary_tree.pxi\", line 1191, in sklearn.neighbors._kd_tree.BinaryTree64.query\n  File \"sklearn\\\\neighbors\\\\_binary_tree.pxi\", line 524, in sklearn.neighbors._kd_tree.NeighborsHeap64.__init__\n  File \"x:\\Data Science\\deep_env\\lib\\site-packages\\numpy\\_core\\numeric.py\", line 361, in full\n    a = empty(shape, dtype, order, device=device)\nnumpy._core._exceptions._ArrayMemoryError: Unable to allocate 97.7 MiB for an array with shape (3201247, 4) and data type float64\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mutual_info_classif\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Compute Information Gain (IG)\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m ig_scores \u001b[38;5;241m=\u001b[39m \u001b[43mmutual_info_classif\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Parallel Processing\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Create a DataFrame to Store IG Values\u001b[39;00m\n\u001b[0;32m      7\u001b[0m ig_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature\u001b[39m\u001b[38;5;124m\"\u001b[39m: X\u001b[38;5;241m.\u001b[39mcolumns, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInformation Gain\u001b[39m\u001b[38;5;124m\"\u001b[39m: ig_scores})\n",
      "File \u001b[1;32mx:\\Data Science\\deep_env\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    214\u001b[0m         )\n\u001b[0;32m    215\u001b[0m     ):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    226\u001b[0m     )\n",
      "File \u001b[1;32mx:\\Data Science\\deep_env\\lib\\site-packages\\sklearn\\feature_selection\\_mutual_info.py:571\u001b[0m, in \u001b[0;36mmutual_info_classif\u001b[1;34m(X, y, discrete_features, n_neighbors, copy, random_state, n_jobs)\u001b[0m\n\u001b[0;32m    475\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Estimate mutual information for a discrete target variable.\u001b[39;00m\n\u001b[0;32m    476\u001b[0m \n\u001b[0;32m    477\u001b[0m \u001b[38;5;124;03mMutual information (MI) [1]_ between two random variables is a non-negative\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;124;03m       0.     , 0.     , 0.     , 0.      , 0.        ])\u001b[39;00m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    570\u001b[0m check_classification_targets(y)\n\u001b[1;32m--> 571\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_estimate_mi\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    572\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    573\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    574\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdiscrete_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdiscrete_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    575\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdiscrete_target\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    576\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_neighbors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_neighbors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    577\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    578\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    579\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    580\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mx:\\Data Science\\deep_env\\lib\\site-packages\\sklearn\\feature_selection\\_mutual_info.py:317\u001b[0m, in \u001b[0;36m_estimate_mi\u001b[1;34m(X, y, discrete_features, discrete_target, n_neighbors, copy, random_state, n_jobs)\u001b[0m\n\u001b[0;32m    310\u001b[0m     y \u001b[38;5;241m=\u001b[39m scale(y, with_mean\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    311\u001b[0m     y \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    312\u001b[0m         \u001b[38;5;241m1e-10\u001b[39m\n\u001b[0;32m    313\u001b[0m         \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mmaximum(\u001b[38;5;241m1\u001b[39m, np\u001b[38;5;241m.\u001b[39mmean(np\u001b[38;5;241m.\u001b[39mabs(y)))\n\u001b[0;32m    314\u001b[0m         \u001b[38;5;241m*\u001b[39m rng\u001b[38;5;241m.\u001b[39mstandard_normal(size\u001b[38;5;241m=\u001b[39mn_samples)\n\u001b[0;32m    315\u001b[0m     )\n\u001b[1;32m--> 317\u001b[0m mi \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_compute_mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscrete_feature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscrete_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_neighbors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscrete_feature\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_iterate_columns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscrete_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(mi)\n",
      "File \u001b[1;32mx:\\Data Science\\deep_env\\lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     76\u001b[0m )\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mx:\\Data Science\\deep_env\\lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mx:\\Data Science\\deep_env\\lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mx:\\Data Science\\deep_env\\lib\\site-packages\\joblib\\parallel.py:1754\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_retrieval():\n\u001b[0;32m   1748\u001b[0m \n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[0;32m   1751\u001b[0m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[0;32m   1752\u001b[0m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborting:\n\u001b[1;32m-> 1754\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1755\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1757\u001b[0m     \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m     \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[1;32mx:\\Data Science\\deep_env\\lib\\site-packages\\joblib\\parallel.py:1789\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1785\u001b[0m \u001b[38;5;66;03m# If this error job exists, immediately raise the error by\u001b[39;00m\n\u001b[0;32m   1786\u001b[0m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[0;32m   1788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1789\u001b[0m     \u001b[43merror_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mx:\\Data Science\\deep_env\\lib\\site-packages\\joblib\\parallel.py:745\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    739\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_backend\n\u001b[0;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msupports_retrieve_callback:\n\u001b[0;32m    742\u001b[0m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[0;32m    743\u001b[0m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[0;32m    744\u001b[0m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[1;32m--> 745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mx:\\Data Science\\deep_env\\lib\\site-packages\\joblib\\parallel.py:763\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    762\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m TASK_ERROR:\n\u001b[1;32m--> 763\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    765\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 97.7 MiB for an array with shape (3201247, 4) and data type float64"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "# Compute Information Gain (IG)\n",
    "ig_scores = mutual_info_classif(X, y, random_state=42, n_jobs=-1)  # Parallel Processing\n",
    "\n",
    "# Create a DataFrame to Store IG Values\n",
    "ig_df = pd.DataFrame({\"Feature\": X.columns, \"Information Gain\": ig_scores})\n",
    "\n",
    "#  Sort Features by IG Score (Descending Order)\n",
    "ig_df = ig_df.sort_values(by=\"Information Gain\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "#  Display Results\n",
    "print(\"‚úÖ IG Calculation Completed!\")\n",
    "print(ig_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ IG Calculation Results Saved Successfully as thesis_main_ig_calculation.csv!\n"
     ]
    }
   ],
   "source": [
    "# Save IG results to CSV\n",
    "ig_df.to_csv(\"thesis_main_ig_calculation.csv\", index=False)\n",
    "\n",
    "print(\"‚úÖ IG Calculation Results Saved Successfully as thesis_main_ig_calculation.csv!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Paper Implementation (For Selecting IG Method)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fixed Threshold Method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Features Selected by Fixed Threshold Method (Median-Based):\n",
      "['pH' 'Color_Near Colorless' 'Manganese' 'Turbidity' 'Chloride' 'Copper'\n",
      " 'Odor' 'Color_Faint Yellow' 'Color_Yellow' 'Nitrate' 'Chlorine'\n",
      " 'Fluoride' 'Iron' 'Total Dissolved Solids' 'Color_Light Yellow' 'Sulfate'\n",
      " 'Source_Well' 'Time of Day' 'Source_Stream' 'Source_Lake' 'Source_River']\n",
      "üìå Number of Features Selected: 21\n"
     ]
    }
   ],
   "source": [
    "# Use the 50th percentile (median) as the fixed threshold\n",
    "fixed_threshold = np.percentile(ig_df[\"Information Gain\"], 50)  \n",
    "\n",
    "# Select features with IG >= fixed threshold\n",
    "selected_features_fixed = ig_df.loc[ig_df[\"Information Gain\"] >= fixed_threshold, \"Feature\"].values\n",
    "\n",
    "# Display Results\n",
    "print(\"\\n‚úÖ Features Selected by Fixed Threshold Method (Median-Based):\")\n",
    "print(selected_features_fixed)\n",
    "print(f\"üìå Number of Features Selected: {len(selected_features_fixed)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Standard Deviation-Based Threshold Approach**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Features Selected by Standard Deviation Threshold Method:\n",
      "['pH' 'Color_Near Colorless' 'Manganese' 'Turbidity' 'Chloride' 'Copper'\n",
      " 'Odor' 'Color_Faint Yellow' 'Color_Yellow' 'Nitrate' 'Chlorine'\n",
      " 'Fluoride' 'Iron' 'Total Dissolved Solids' 'Color_Light Yellow' 'Sulfate'\n",
      " 'Source_Well' 'Time of Day' 'Source_Stream' 'Source_Lake' 'Source_River'\n",
      " 'Source_Reservoir' 'Source_Ground' 'Source_Spring' 'Zinc']\n",
      "üìå Number of Features Selected: 25\n"
     ]
    }
   ],
   "source": [
    "# Calculate the threshold as the standard deviation of IG values\n",
    "std_threshold = ig_df[\"Information Gain\"].std()\n",
    "\n",
    "# Select features with IG >= standard deviation threshold\n",
    "selected_features_std = ig_df.loc[ig_df[\"Information Gain\"] >= std_threshold, \"Feature\"].values\n",
    "\n",
    "# Display Results\n",
    "print(\"\\n‚úÖ Features Selected by Standard Deviation Threshold Method:\")\n",
    "print(selected_features_std)\n",
    "print(f\"üìå Number of Features Selected: {len(selected_features_std)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CBFS Method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Features Selected by CBFS Method:\n",
      "Index(['pH', 'Iron', 'Nitrate', 'Chloride', 'Zinc', 'Turbidity', 'Fluoride',\n",
      "       'Copper', 'Odor', 'Sulfate', 'Chlorine', 'Manganese',\n",
      "       'Total Dissolved Solids'],\n",
      "      dtype='object')\n",
      "üìå Number of Features Selected: 13\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# Train Random Forest on the dataset\n",
    "rf = RandomForestClassifier(n_estimators=100, max_features=\"sqrt\", random_state=42, n_jobs=-1)\n",
    "rf.fit(X, y)\n",
    "\n",
    "# Apply CBFS: Select features with importance >= mean importance\n",
    "cbfs = SelectFromModel(rf, threshold=\"mean\", prefit=False)\n",
    "cbfs.fit(X, y)  # Fit before selecting features\n",
    "selected_features_cbfs = X.columns[cbfs.get_support()]\n",
    "\n",
    "# Display Results\n",
    "print(\"\\n‚úÖ Features Selected by CBFS Method:\")\n",
    "print(selected_features_cbfs)\n",
    "print(f\"üìå Number of Features Selected: {len(selected_features_cbfs)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FFT Method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Features Selected by FFT with Proposed Threshold:\n",
      "Index(['Color_Faint Yellow', 'Color_Light Yellow', 'Color_Near Colorless',\n",
      "       'Color_Yellow', 'Source_Ground', 'Source_Lake', 'Source_Reservoir',\n",
      "       'Source_River', 'Source_Spring', 'Source_Stream', 'Source_Well',\n",
      "       'Month_August', 'Month_December', 'Month_February', 'Month_January',\n",
      "       'Month_July', 'Month_June', 'Month_March', 'Month_May',\n",
      "       'Month_November', 'Month_October', 'Month_September'],\n",
      "      dtype='object')\n",
      "Number of Features: 22\n"
     ]
    }
   ],
   "source": [
    "from scipy.fft import fft, ifft\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Apply FFT transformation to the dataset (keeping real part)\n",
    "X_fft = fft(X, axis=0).real  \n",
    "\n",
    "# Step 2: Apply IFFT to bring the data back to original form\n",
    "X_ifft = ifft(X_fft, axis=0).real  \n",
    "\n",
    "# Step 3: Compute Information Gain (IG) on transformed data\n",
    "information_gain_fft = mutual_info_classif(X_ifft, y, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Step 4: Compute standard deviation threshold\n",
    "fft_threshold = np.std(information_gain_fft)  \n",
    "\n",
    "# Step 5: Select features with IG >= threshold\n",
    "selected_features_fft = X.columns[information_gain_fft >= fft_threshold]\n",
    "\n",
    "print(\"\\nFeatures Selected by FFT with Proposed Threshold:\")\n",
    "print(selected_features_fft)\n",
    "print(f\"Number of Features: {len(selected_features_fft)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Feature Selection Analysis Summary**  \n",
    "\n",
    "We applied four different **Information Gain (IG)-based** feature selection methods, each emphasizing different types of features. Below is a structured analysis of their outcomes.  \n",
    "\n",
    "---\n",
    "\n",
    "### **üîç Overview of Selected Features**  \n",
    "\n",
    "| **Method**                 | **Selected Features** | **Key Characteristics** |\n",
    "|---------------------------|---------------------|------------------------|\n",
    "| **Fixed Threshold (Median-Based)** | 21 features | Focused on **chemical properties** (`pH`, `Iron`, `Nitrate`, etc.) with some categorical (`Color_*`, `Source_*`). |\n",
    "| **Standard Deviation-Based Threshold** | 25 features | Similar to Fixed, but included additional **source-based** features (`Source_*`). |\n",
    "| **CBFS (Random Forest-Based)** | 13 features | Strictly **chemical-based**, ignoring categorical/time-related variables. |\n",
    "| **FFT-Based Selection** | 22 features | Selected mostly **categorical (Color, Source) & temporal (Month) features**, ignoring key chemical indicators. |\n",
    "\n",
    "---\n",
    "\n",
    "### **üìå Observations & Trends**  \n",
    "\n",
    "#### **‚úÖ What‚Äôs Being Prioritized?**  \n",
    "‚úî **Fixed & Std-Dev Thresholds:**  \n",
    "   - Prioritize **core water quality indicators** (`pH`, `Iron`, `Nitrate`, `Turbidity`).  \n",
    "   - Include some categorical features (`Color_*`, `Source_*`).  \n",
    "‚úî **CBFS:**  \n",
    "   - Selects **only chemical properties**, emphasizing direct pollutant measurements.  \n",
    "‚úî **FFT:**  \n",
    "   - Detects **seasonal patterns & categorical dependencies**, prioritizing `Month_*` and `Source_*` over chemical values.  \n",
    "\n",
    "---\n",
    "\n",
    "### **‚ö†Ô∏è What‚Äôs Being Ignored?**  \n",
    "‚ùå **CBFS & Threshold-Based Methods:**  \n",
    "   - **Completely ignore** time-based (`Month_*`) and source-based (`Source_*`) variables, possibly **overlooking seasonal variations**.  \n",
    "‚ùå **FFT-Based Selection:**  \n",
    "   - **Fails to capture key chemical indicators** (e.g., `pH`, `Iron`, `Nitrate`), likely because **chemical values don‚Äôt follow strong periodic patterns**.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Phase 3: DWTM Paper Implement !**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Now The plan is:**  \n",
    "\n",
    "1Ô∏è‚É£ **Use all Feature Selection (FS) methods** we implemented.  \n",
    "2Ô∏è‚É£ **Convert selected features** following the approach in the same way as the paper.  \n",
    "3Ô∏è‚É£ **Apply models** on all feature sets to compare initial performance.  \n",
    "4Ô∏è‚É£ **Analyze performance trends** and select the best FS method for further refinements.  \n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Standard Deviation-Based Threshold**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'selected_features_std' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Extract only selected features + Target variable\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df_dwtm \u001b[38;5;241m=\u001b[39m df[\u001b[43mselected_features_std\u001b[49m\u001b[38;5;241m.\u001b[39mtolist() \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Display shape & first few rows for verification\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m‚úÖ DWTM Data Prepared!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'selected_features_std' is not defined"
     ]
    }
   ],
   "source": [
    "# Extract only selected features + Target variable\n",
    "df_dwtm = df[selected_features_std.tolist() + [\"Target\"]]\n",
    "\n",
    "# Display shape & first few rows for verification\n",
    "print(\"\\n‚úÖ DWTM Data Prepared!\")\n",
    "print(\"üìå Updated Dataset Shape:\", df_dwtm.shape)\n",
    "print(\"üìù First 5 Rows:\")\n",
    "print(df_dwtm.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
