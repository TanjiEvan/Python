{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d070051c",
   "metadata": {},
   "source": [
    "## **Word Embedding**\n",
    "\n",
    "---\n",
    "\n",
    "### **What is Word Embedding?**\n",
    "\n",
    "**Word Embedding** is a way to represent words as **dense vectors of real numbers**.\n",
    "\n",
    "Unlike BoW or TF-IDF (which are sparse and high-dimensional), embeddings **capture meaning** and **relationships** between words.\n",
    "\n",
    "---\n",
    "\n",
    "### **Why Use Word Embedding?**\n",
    "\n",
    "* Captures **semantic meaning** (e.g., \"king\" and \"queen\" are related).\n",
    "* Words with similar meanings have **similar vector representations**.\n",
    "* More efficient and powerful for deep learning models.\n",
    "\n",
    "---\n",
    "\n",
    "### **Real Example:**\n",
    "\n",
    "In a well-trained embedding space:\n",
    "\n",
    "* `vec(\"king\") - vec(\"man\") + vec(\"woman\") â‰ˆ vec(\"queen\")`\n",
    "* This shows it understands **gender relationships** and **roles**.\n",
    "\n",
    "---\n",
    "\n",
    "### **Common Word Embedding Models**\n",
    "\n",
    "| Model    | Description                             |\n",
    "| -------- | --------------------------------------- |\n",
    "| Word2Vec | Learns word relationships using context |\n",
    "| GloVe    | Captures global word co-occurrence      |\n",
    "| FastText | Like Word2Vec but includes subword info |\n",
    "| BERT     | Contextual word embeddings (advanced)   |\n",
    "\n",
    "---\n",
    "\n",
    "### **Summary**\n",
    "\n",
    "| Aspect      | Details                                        |\n",
    "| ----------- | ---------------------------------------------- |\n",
    "| Vector type | Dense (real-valued, low-dimensional)           |\n",
    "| Advantage   | Captures meaning, relationships                |\n",
    "| Use cases   | NLP, sentiment analysis, chatbots, translation |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fbefa8",
   "metadata": {},
   "source": [
    "> Embedding = a special kind of number that understands the word."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1c6d44",
   "metadata": {},
   "source": [
    "## **1. Word2Vec**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c457394d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### **What is Word2Vec?**\n",
    "\n",
    "**Word2Vec** is a popular word embedding technique that converts words into dense vectors.\n",
    "It learns these vectors by predicting words based on their surrounding words (context).\n",
    "\n",
    "---\n",
    "\n",
    "### **Why Use Word2Vec?**\n",
    "\n",
    "* Captures **semantic relationships** between words.\n",
    "* Words used in similar contexts get **similar vectors**.\n",
    "* Helps machines understand meaning, not just word counts.\n",
    "\n",
    "---\n",
    "\n",
    "### **How Does Word2Vec Work?**\n",
    "\n",
    "Two main models:\n",
    "\n",
    "* **CBOW (Continuous Bag of Words):** Predicts a word based on its context (neighboring words).\n",
    "* **Skip-gram:** Predicts the context given a word.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### **Summary**\n",
    "\n",
    "| Aspect    | Details                                             |\n",
    "| --------- | --------------------------------------------------- |\n",
    "| Goal      | Learn word vectors capturing context                |\n",
    "| Models    | CBOW and Skip-gram                                  |\n",
    "| Output    | Dense vector for each word                          |\n",
    "| Use cases | NLP tasks like sentiment analysis, search, chatbots |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdfc1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.3.3-cp310-cp310-win_amd64.whl.metadata (8.2 kB)\n",
      "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
      "  Using cached numpy-1.26.4-cp310-cp310-win_amd64.whl.metadata (61 kB)\n",
      "Collecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
      "  Downloading scipy-1.13.1-cp310-cp310-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in x:\\data science\\deep_env\\lib\\site-packages (from gensim) (7.1.0)\n",
      "Requirement already satisfied: wrapt in x:\\data science\\deep_env\\lib\\site-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
      "Downloading gensim-4.3.3-cp310-cp310-win_amd64.whl (24.0 MB)\n",
      "   ---------------------------------------- 0.0/24.0 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.5/24.0 MB 5.6 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 1.8/24.0 MB 5.3 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 2.9/24.0 MB 5.2 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 3.9/24.0 MB 5.5 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 5.2/24.0 MB 5.5 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 6.6/24.0 MB 5.6 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 7.9/24.0 MB 5.7 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 8.9/24.0 MB 5.8 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 10.2/24.0 MB 5.8 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 11.5/24.0 MB 5.9 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 13.1/24.0 MB 6.0 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 14.4/24.0 MB 6.0 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 15.7/24.0 MB 6.1 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 17.0/24.0 MB 6.2 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 18.6/24.0 MB 6.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 19.9/24.0 MB 6.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 20.7/24.0 MB 6.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 21.5/24.0 MB 6.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 22.3/24.0 MB 5.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 22.8/24.0 MB 5.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 23.3/24.0 MB 5.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  23.9/24.0 MB 5.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 24.0/24.0 MB 5.4 MB/s eta 0:00:00\n",
      "Using cached numpy-1.26.4-cp310-cp310-win_amd64.whl (15.8 MB)\n",
      "Downloading scipy-1.13.1-cp310-cp310-win_amd64.whl (46.2 MB)\n",
      "   ---------------------------------------- 0.0/46.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.5/46.2 MB 2.8 MB/s eta 0:00:17\n",
      "    --------------------------------------- 1.0/46.2 MB 3.0 MB/s eta 0:00:16\n",
      "   - -------------------------------------- 1.8/46.2 MB 3.0 MB/s eta 0:00:16\n",
      "   -- ------------------------------------- 2.4/46.2 MB 3.0 MB/s eta 0:00:15\n",
      "   -- ------------------------------------- 2.9/46.2 MB 2.9 MB/s eta 0:00:15\n",
      "   -- ------------------------------------- 3.4/46.2 MB 2.8 MB/s eta 0:00:16\n",
      "   --- ------------------------------------ 3.9/46.2 MB 2.7 MB/s eta 0:00:16\n",
      "   --- ------------------------------------ 4.5/46.2 MB 2.7 MB/s eta 0:00:16\n",
      "   ---- ----------------------------------- 4.7/46.2 MB 2.7 MB/s eta 0:00:16\n",
      "   ---- ----------------------------------- 5.5/46.2 MB 2.6 MB/s eta 0:00:16\n",
      "   ---- ----------------------------------- 5.8/46.2 MB 2.6 MB/s eta 0:00:16\n",
      "   ----- ---------------------------------- 6.3/46.2 MB 2.6 MB/s eta 0:00:16\n",
      "   ------ --------------------------------- 7.1/46.2 MB 2.6 MB/s eta 0:00:15\n",
      "   ------ --------------------------------- 7.6/46.2 MB 2.6 MB/s eta 0:00:15\n",
      "   ------- -------------------------------- 8.1/46.2 MB 2.6 MB/s eta 0:00:15\n",
      "   ------- -------------------------------- 8.7/46.2 MB 2.6 MB/s eta 0:00:15\n",
      "   ------- -------------------------------- 9.2/46.2 MB 2.6 MB/s eta 0:00:15\n",
      "   -------- ------------------------------- 9.7/46.2 MB 2.6 MB/s eta 0:00:14\n",
      "   --------- ------------------------------ 10.5/46.2 MB 2.7 MB/s eta 0:00:14\n",
      "   --------- ------------------------------ 11.0/46.2 MB 2.7 MB/s eta 0:00:14\n",
      "   ---------- ----------------------------- 11.8/46.2 MB 2.7 MB/s eta 0:00:13\n",
      "   ---------- ----------------------------- 12.3/46.2 MB 2.7 MB/s eta 0:00:13\n",
      "   ----------- ---------------------------- 13.1/46.2 MB 2.7 MB/s eta 0:00:13\n",
      "   ----------- ---------------------------- 13.6/46.2 MB 2.8 MB/s eta 0:00:12\n",
      "   ------------ --------------------------- 14.4/46.2 MB 2.8 MB/s eta 0:00:12\n",
      "   ------------ --------------------------- 14.9/46.2 MB 2.8 MB/s eta 0:00:12\n",
      "   ------------- -------------------------- 15.5/46.2 MB 2.8 MB/s eta 0:00:12\n",
      "   ------------- -------------------------- 16.0/46.2 MB 2.8 MB/s eta 0:00:11\n",
      "   -------------- ------------------------- 16.5/46.2 MB 2.8 MB/s eta 0:00:11\n",
      "   -------------- ------------------------- 17.3/46.2 MB 2.8 MB/s eta 0:00:11\n",
      "   --------------- ------------------------ 17.8/46.2 MB 2.8 MB/s eta 0:00:11\n",
      "   --------------- ------------------------ 18.4/46.2 MB 2.8 MB/s eta 0:00:11\n",
      "   ---------------- ----------------------- 19.1/46.2 MB 2.8 MB/s eta 0:00:10\n",
      "   ----------------- ---------------------- 19.7/46.2 MB 2.8 MB/s eta 0:00:10\n",
      "   ----------------- ---------------------- 20.2/46.2 MB 2.8 MB/s eta 0:00:10\n",
      "   ------------------ --------------------- 21.0/46.2 MB 2.8 MB/s eta 0:00:09\n",
      "   ------------------ --------------------- 21.8/46.2 MB 2.8 MB/s eta 0:00:09\n",
      "   ------------------- -------------------- 22.3/46.2 MB 2.8 MB/s eta 0:00:09\n",
      "   ------------------- -------------------- 23.1/46.2 MB 2.9 MB/s eta 0:00:09\n",
      "   -------------------- ------------------- 23.6/46.2 MB 2.9 MB/s eta 0:00:08\n",
      "   --------------------- ------------------ 24.4/46.2 MB 2.9 MB/s eta 0:00:08\n",
      "   --------------------- ------------------ 25.2/46.2 MB 2.9 MB/s eta 0:00:08\n",
      "   ---------------------- ----------------- 25.7/46.2 MB 2.9 MB/s eta 0:00:08\n",
      "   ---------------------- ----------------- 26.5/46.2 MB 2.9 MB/s eta 0:00:07\n",
      "   ----------------------- ---------------- 27.3/46.2 MB 2.9 MB/s eta 0:00:07\n",
      "   ------------------------ --------------- 27.8/46.2 MB 2.9 MB/s eta 0:00:07\n",
      "   ------------------------ --------------- 28.6/46.2 MB 2.9 MB/s eta 0:00:06\n",
      "   ------------------------- -------------- 29.4/46.2 MB 3.0 MB/s eta 0:00:06\n",
      "   -------------------------- ------------- 30.1/46.2 MB 3.0 MB/s eta 0:00:06\n",
      "   -------------------------- ------------- 30.9/46.2 MB 3.0 MB/s eta 0:00:06\n",
      "   --------------------------- ------------ 31.5/46.2 MB 3.0 MB/s eta 0:00:05\n",
      "   --------------------------- ------------ 32.2/46.2 MB 3.0 MB/s eta 0:00:05\n",
      "   ---------------------------- ----------- 33.3/46.2 MB 3.0 MB/s eta 0:00:05\n",
      "   ----------------------------- ---------- 34.1/46.2 MB 3.0 MB/s eta 0:00:04\n",
      "   ------------------------------ --------- 34.9/46.2 MB 3.1 MB/s eta 0:00:04\n",
      "   ------------------------------ --------- 35.7/46.2 MB 3.1 MB/s eta 0:00:04\n",
      "   ------------------------------- -------- 36.4/46.2 MB 3.1 MB/s eta 0:00:04\n",
      "   -------------------------------- ------- 37.5/46.2 MB 3.1 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 38.3/46.2 MB 3.1 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 39.1/46.2 MB 3.2 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 40.1/46.2 MB 3.2 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 41.2/46.2 MB 3.2 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 41.9/46.2 MB 3.2 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 42.7/46.2 MB 3.2 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 43.8/46.2 MB 3.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 44.8/46.2 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  45.6/46.2 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 46.2/46.2 MB 3.3 MB/s eta 0:00:00\n",
      "Installing collected packages: numpy, scipy, gensim\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.0.2\n",
      "    Uninstalling numpy-2.0.2:\n",
      "      Successfully uninstalled numpy-2.0.2\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.15.1\n",
      "    Uninstalling scipy-1.15.1:\n",
      "      Successfully uninstalled scipy-1.15.1\n",
      "Successfully installed gensim-4.3.3 numpy-1.26.4 scipy-1.13.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -umpy (x:\\data science\\deep_env\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (x:\\data science\\deep_env\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (x:\\data science\\deep_env\\lib\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "bnltk 0.7.8 requires numpy==2.0.2, but you have numpy 1.26.4 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Install the Gensim library (only needs to be done once)\n",
    "#pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be681ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Import necessary modules\n",
    "import gensim # Main library\n",
    "from gensim.models import Word2Vec,keyedvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b796cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Import Gensim's downloader to load pre-trained models easily\n",
    "import gensim.downloader as api\n",
    "\n",
    "# Step 4: Load the Google News Word2Vec model (pre-trained on ~100 billion words)\n",
    "# This is a huge model (~1.6 gb) and it will take some time to load\n",
    "model = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc3b9c90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00350952,  0.01623535, -0.08154297,  0.12792969,  0.11230469,\n",
       "       -0.00534058,  0.03063965,  0.04931641,  0.22070312,  0.07373047,\n",
       "       -0.13769531,  0.16210938,  0.02148438, -0.09375   , -0.12792969,\n",
       "       -0.12402344, -0.11132812,  0.11816406, -0.07861328,  0.25390625,\n",
       "        0.01794434,  0.14160156,  0.0612793 , -0.08691406,  0.07763672,\n",
       "        0.05175781, -0.24609375, -0.17578125,  0.14746094,  0.06640625,\n",
       "       -0.03833008, -0.09033203, -0.07226562,  0.09375   , -0.18847656,\n",
       "        0.06347656,  0.24121094,  0.00714111, -0.30273438, -0.02478027,\n",
       "       -0.09619141, -0.30859375, -0.06054688,  0.22167969,  0.07763672,\n",
       "        0.05834961,  0.15527344, -0.13476562, -0.00341797, -0.13964844,\n",
       "       -0.02905273,  0.03833008, -0.15332031, -0.20996094,  0.21679688,\n",
       "        0.01171875, -0.078125  ,  0.00402832, -0.23535156, -0.10400391,\n",
       "        0.08837891,  0.25976562,  0.02709961,  0.01123047,  0.12988281,\n",
       "       -0.11914062, -0.07861328, -0.04736328, -0.06591797,  0.07958984,\n",
       "        0.04321289, -0.14355469,  0.04150391,  0.20410156,  0.05493164,\n",
       "       -0.06030273,  0.10107422, -0.00439453,  0.32617188, -0.05712891,\n",
       "       -0.09130859,  0.20019531,  0.02941895, -0.11230469,  0.06054688,\n",
       "       -0.00982666, -0.30664062, -0.02514648,  0.14355469,  0.07275391,\n",
       "        0.09716797, -0.09179688, -0.20410156, -0.21875   ,  0.07128906,\n",
       "        0.16503906, -0.01300049,  0.10888672, -0.09326172, -0.07568359,\n",
       "       -0.07568359, -0.15136719,  0.0625    , -0.09179688,  0.06176758,\n",
       "        0.01086426, -0.21484375, -0.12353516,  0.14453125,  0.02001953,\n",
       "        0.07910156,  0.33398438,  0.06640625, -0.08056641,  0.16699219,\n",
       "       -0.2421875 ,  0.0090332 , -0.14453125,  0.18066406,  0.21289062,\n",
       "        0.04077148,  0.171875  , -0.03100586, -0.12597656, -0.0625    ,\n",
       "       -0.13476562, -0.15820312,  0.11816406, -0.06591797, -0.10058594,\n",
       "       -0.15234375,  0.14550781, -0.14941406,  0.22070312,  0.04907227,\n",
       "        0.01281738,  0.00927734,  0.20019531, -0.15429688,  0.16308594,\n",
       "       -0.04907227, -0.16015625,  0.0177002 , -0.08544922,  0.23828125,\n",
       "       -0.11572266,  0.08154297, -0.38867188, -0.19433594,  0.33203125,\n",
       "       -0.12597656,  0.02819824,  0.14550781, -0.14160156,  0.08105469,\n",
       "        0.09619141, -0.00897217, -0.15332031,  0.15332031, -0.0088501 ,\n",
       "       -0.10498047,  0.04638672,  0.25195312,  0.09179688, -0.0300293 ,\n",
       "       -0.14355469, -0.01123047, -0.11865234,  0.12109375,  0.11572266,\n",
       "       -0.00640869,  0.05419922,  0.06884766, -0.08837891,  0.04589844,\n",
       "        0.00335693, -0.18164062,  0.02160645, -0.04370117, -0.0559082 ,\n",
       "       -0.13574219, -0.09375   ,  0.02600098, -0.13964844, -0.06542969,\n",
       "       -0.04858398,  0.41796875,  0.18554688,  0.18554688,  0.21875   ,\n",
       "       -0.09277344,  0.23925781,  0.00125885, -0.05102539, -0.20605469,\n",
       "        0.07128906, -0.04418945, -0.08056641,  0.02978516, -0.08007812,\n",
       "       -0.04296875, -0.18945312, -0.05810547, -0.0135498 ,  0.09765625,\n",
       "       -0.10644531, -0.02185059,  0.31445312,  0.04248047,  0.03491211,\n",
       "       -0.07861328,  0.27148438,  0.07275391, -0.12304688,  0.0291748 ,\n",
       "       -0.04736328,  0.11279297, -0.16503906,  0.05224609,  0.06933594,\n",
       "       -0.06542969, -0.02587891,  0.19824219, -0.16601562,  0.13867188,\n",
       "        0.01422119, -0.10791016,  0.0324707 ,  0.03442383,  0.05981445,\n",
       "        0.06738281, -0.01940918, -0.10742188, -0.00454712, -0.27539062,\n",
       "        0.00604248,  0.15917969, -0.06835938,  0.00086975, -0.07177734,\n",
       "        0.0625    , -0.13671875, -0.06591797, -0.23828125, -0.03466797,\n",
       "       -0.08105469, -0.05761719,  0.20410156, -0.01226807, -0.14257812,\n",
       "       -0.16113281,  0.17480469,  0.03662109,  0.12890625,  0.09082031,\n",
       "        0.0546875 , -0.24511719, -0.00866699, -0.05615234, -0.06933594,\n",
       "        0.01916504,  0.11865234, -0.06005859, -0.0859375 ,  0.01940918,\n",
       "       -0.02270508, -0.0612793 ,  0.06982422,  0.17285156,  0.17773438,\n",
       "        0.04370117,  0.05615234,  0.02734375,  0.2578125 ,  0.19433594,\n",
       "       -0.04003906, -0.12158203, -0.10839844, -0.17773438,  0.05249023,\n",
       "       -0.11376953, -0.11230469,  0.27148438, -0.00061417,  0.0168457 ,\n",
       "       -0.11816406, -0.03833008, -0.04223633, -0.12109375, -0.12695312,\n",
       "        0.00222778, -0.20019531, -0.1328125 ,  0.09960938, -0.2734375 ,\n",
       "       -0.328125  , -0.22460938, -0.14746094, -0.02368164,  0.24902344],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[\"King\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06b2f88e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[\"King\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8f6ed82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.22070312, -0.17480469, -0.10498047,  0.2578125 ,  0.16210938,\n",
       "       -0.13085938, -0.16699219,  0.07373047, -0.07226562,  0.02404785,\n",
       "       -0.13964844,  0.02197266,  0.17675781, -0.19140625,  0.0378418 ,\n",
       "       -0.01782227, -0.03710938, -0.03735352,  0.15625   ,  0.08837891,\n",
       "        0.0534668 , -0.02392578, -0.2734375 , -0.2578125 , -0.00720215,\n",
       "        0.06933594, -0.21777344, -0.10058594,  0.2421875 ,  0.03417969,\n",
       "       -0.12890625, -0.1171875 , -0.18261719,  0.04321289, -0.125     ,\n",
       "       -0.09960938,  0.26367188,  0.375     , -0.32421875, -0.1328125 ,\n",
       "       -0.13378906, -0.50390625, -0.05908203,  0.04077148,  0.23730469,\n",
       "       -0.03393555, -0.01495361, -0.09765625, -0.06445312,  0.02087402,\n",
       "       -0.10302734,  0.10449219,  0.20019531, -0.16503906, -0.01196289,\n",
       "        0.30859375, -0.41015625, -0.22070312,  0.08056641, -0.12792969,\n",
       "        0.13085938,  0.28515625, -0.07275391,  0.02612305,  0.01916504,\n",
       "       -0.16992188,  0.01745605,  0.13085938, -0.17089844, -0.10107422,\n",
       "        0.10791016,  0.0035553 ,  0.0300293 , -0.12792969,  0.17285156,\n",
       "       -0.06079102,  0.02990723,  0.08544922,  0.22363281, -0.03344727,\n",
       "       -0.28125   , -0.02307129,  0.0559082 , -0.3125    , -0.0098877 ,\n",
       "       -0.01306152, -0.37695312,  0.10253906,  0.20605469,  0.12890625,\n",
       "       -0.09960938, -0.06494141,  0.01446533, -0.09375   ,  0.15234375,\n",
       "        0.21777344,  0.17871094,  0.02783203, -0.0390625 ,  0.10986328,\n",
       "       -0.12158203, -0.18945312,  0.01867676, -0.13476562, -0.16992188,\n",
       "       -0.15234375, -0.33789062, -0.13183594,  0.08935547, -0.14355469,\n",
       "        0.06738281,  0.29882812,  0.24316406,  0.078125  ,  0.30859375,\n",
       "       -0.08789062,  0.16015625, -0.4140625 ,  0.3046875 ,  0.15722656,\n",
       "       -0.01275635, -0.03735352,  0.08496094, -0.3359375 , -0.06640625,\n",
       "       -0.04492188, -0.25390625,  0.01293945, -0.14160156,  0.02941895,\n",
       "        0.09179688,  0.2265625 , -0.25195312,  0.01416016,  0.21875   ,\n",
       "        0.16796875, -0.1015625 , -0.05395508, -0.09912109, -0.14160156,\n",
       "       -0.01519775, -0.02954102,  0.08154297, -0.1796875 ,  0.32226562,\n",
       "        0.03686523, -0.02050781, -0.07519531, -0.08642578, -0.08740234,\n",
       "       -0.01428223, -0.05126953,  0.16699219, -0.10498047, -0.05834961,\n",
       "       -0.08837891, -0.00376892, -0.00300598,  0.1875    , -0.25      ,\n",
       "        0.0390625 ,  0.12597656,  0.30859375, -0.00805664, -0.10791016,\n",
       "       -0.08740234, -0.26953125, -0.3984375 , -0.02978516,  0.04003906,\n",
       "       -0.07421875,  0.16601562,  0.22851562,  0.1796875 , -0.16894531,\n",
       "       -0.06445312, -0.07958984,  0.04663086, -0.11865234, -0.17382812,\n",
       "       -0.11572266, -0.10009766,  0.10107422, -0.203125  , -0.08105469,\n",
       "       -0.04638672,  0.375     ,  0.24902344, -0.16210938,  0.08105469,\n",
       "       -0.35742188,  0.07226562,  0.07080078, -0.00193024, -0.16601562,\n",
       "        0.19140625,  0.34179688,  0.05102539,  0.08300781, -0.07128906,\n",
       "        0.03149414, -0.11523438, -0.06054688,  0.05053711,  0.04345703,\n",
       "       -0.10986328,  0.05834961,  0.43945312,  0.10009766,  0.17480469,\n",
       "        0.0324707 ,  0.13378906,  0.11914062, -0.17675781, -0.07568359,\n",
       "       -0.25      , -0.17578125, -0.25585938,  0.13574219,  0.08789062,\n",
       "        0.16308594, -0.00488281,  0.33203125, -0.26171875, -0.08203125,\n",
       "        0.06225586, -0.08398438, -0.06445312,  0.18359375,  0.10595703,\n",
       "       -0.22558594, -0.1328125 , -0.39257812, -0.05908203,  0.07666016,\n",
       "       -0.06494141,  0.02575684, -0.07226562,  0.20800781, -0.06298828,\n",
       "        0.11572266,  0.10644531,  0.09912109, -0.25      ,  0.02172852,\n",
       "        0.0612793 , -0.16503906,  0.01965332, -0.00946045, -0.2578125 ,\n",
       "        0.02160645, -0.01147461,  0.17773438,  0.33398438,  0.01300049,\n",
       "        0.17675781, -0.31054688,  0.02282715, -0.1875    , -0.13574219,\n",
       "        0.25      ,  0.33984375, -0.15722656, -0.06591797, -0.0378418 ,\n",
       "       -0.09716797, -0.39648438,  0.13085938,  0.03344727,  0.046875  ,\n",
       "       -0.14355469,  0.21777344,  0.22070312,  0.20019531,  0.45507812,\n",
       "       -0.40820312,  0.11767578, -0.09765625, -0.05957031,  0.27929688,\n",
       "        0.125     , -0.3203125 ,  0.17773438,  0.00527954,  0.24902344,\n",
       "       -0.05712891,  0.00637817,  0.00408936, -0.12988281,  0.16894531,\n",
       "        0.05615234, -0.16113281, -0.28515625, -0.06103516, -0.03369141,\n",
       "        0.02600098,  0.03491211, -0.13769531,  0.12060547, -0.09375   ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[\"Queen\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acae2ef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('woman', 0.7664011716842651),\n",
       " ('boy', 0.6824871301651001),\n",
       " ('teenager', 0.6586929559707642),\n",
       " ('teenage_girl', 0.6147903203964233),\n",
       " ('girl', 0.5921714305877686),\n",
       " ('suspected_purse_snatcher', 0.5716364979743958),\n",
       " ('robber', 0.5585119128227234),\n",
       " ('Robbery_suspect', 0.5584410429000854),\n",
       " ('teen_ager', 0.5549196600914001),\n",
       " ('men', 0.5489761233329773)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('man')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbafd55",
   "metadata": {},
   "source": [
    "Here's **how** it works in 2 simple steps:\n",
    "\n",
    "---\n",
    "\n",
    "###  **Step 1:**\n",
    "\n",
    "Word2Vec has a **300-number vector** for `'man'`:\n",
    "\n",
    "```\n",
    "'man' â†’ [0.134, -0.298, ..., 0.072]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 2:**\n",
    "\n",
    "It **compares** this vector to every other wordâ€™s vector in the vocabulary using **cosine similarity**.\n",
    "The ones with **highest similarity score** (like `'woman'`, `'boy'`, `'gentleman'`) are returned as **most similar**.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27a7343e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cricketing', 0.8372227549552917),\n",
       " ('cricketers', 0.8165745735168457),\n",
       " ('Test_cricket', 0.8094819188117981),\n",
       " ('Twenty##_cricket', 0.8068487048149109),\n",
       " ('Twenty##', 0.762426495552063),\n",
       " ('Cricket', 0.7541398406028748),\n",
       " ('cricketer', 0.7372578382492065),\n",
       " ('twenty##', 0.7316358685493469),\n",
       " ('T##_cricket', 0.7304614186286926),\n",
       " ('West_Indies_cricket', 0.698798656463623)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('cricket')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "957c0491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Facebook', 0.7563531398773193),\n",
       " ('FaceBook', 0.7076998949050903),\n",
       " ('twitter', 0.6988552212715149),\n",
       " ('myspace', 0.6941818594932556),\n",
       " ('Twitter', 0.6642445921897888),\n",
       " ('twitter_facebook', 0.6572229862213135),\n",
       " ('Facebook.com', 0.6529869437217712),\n",
       " ('myspace_facebook', 0.6370644569396973),\n",
       " ('facebook_twitter', 0.6367619633674622),\n",
       " ('linkedin', 0.6356592178344727)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('facebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c407fd4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7664013"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similarity('man','woman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a064dac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.046399325"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similarity('man','food')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dcd8423e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09206605"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similarity('woman','food')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6a9343f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'monkey'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.doesnt_match(['PHP','java','monkey'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e05f5c5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'java'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.doesnt_match(['python','java','monkey'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3a73a5cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66062933"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similarity('python','snake')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8773e587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09035955"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similarity('python','programming')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "74d6bce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('king', 0.8449392914772034),\n",
       " ('queen', 0.730051577091217),\n",
       " ('monarch', 0.6454662084579468),\n",
       " ('princess', 0.6156250834465027),\n",
       " ('crown_prince', 0.5818676948547363),\n",
       " ('prince', 0.5777117013931274),\n",
       " ('kings', 0.561366617679596),\n",
       " ('sultan', 0.5376775860786438),\n",
       " ('Queen_Consort', 0.5344247221946716),\n",
       " ('queens', 0.5289887189865112)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = model['king'] - model['man'] + model['woman']\n",
    "model.most_similar(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60dd84c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('INR', 0.7877920269966125),\n",
       " ('Tk', 0.6473284363746643),\n",
       " ('taka', 0.6242390275001526),\n",
       " ('Rs3', 0.5809125900268555),\n",
       " ('Rs###', 0.5680422782897949),\n",
       " ('Rs##', 0.5675228238105774),\n",
       " ('Rs', 0.5669804215431213),\n",
       " ('Rs1', 0.5598682761192322),\n",
       " ('Rs.####', 0.5585658550262451),\n",
       " ('Bangladesh', 0.5535844564437866)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = model['Taka'] - model ['Bangladesh'] + model['India']\n",
    "model.most_similar([vec])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
